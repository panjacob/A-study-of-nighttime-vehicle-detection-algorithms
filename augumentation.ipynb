{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "# import zipfile\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imgaug.augmenters as iaa\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "      iaa.Crop(px=(0, 8), keep_size=True), #Dla obrazka 64px więcej niż 8 to dużo\n",
    "      iaa.Fliplr(0.5),\n",
    "      iaa.GaussianBlur(sigma=(0, 1.0)), #Większy blur polepszy uogólnianie?\n",
    "      iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
    "\n",
    "      iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "        iaa.EdgeDetect(alpha=(0.0, .3)),\n",
    "        iaa.DirectedEdgeDetect(alpha=(0.0, .5), direction=(0.0, 0.5)),\n",
    "      ])),\n",
    "\n",
    "      iaa.Emboss(alpha=(0, 1.0), strength=(0, 0.4)), # Taka maska wyciagajaca fakturę\n",
    "      iaa.Dropout((0.01, 0.1), per_channel=0.5), #Robi czarne kropki\n",
    "      # iaa.CoarseDropout((0.03, 0.15), size_percent=(0.01, 0.03), per_channel=0.2), #Robi czarny kwadrat\n",
    "      iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "      iaa.PiecewiseAffine(scale=(0.01, 0.05)), #Lekkie zniekształcenia\n",
    "      iaa.PerspectiveTransform(scale=(0.01, 0.1)),\n",
    "\n",
    "      iaa.Add((-10, 10), per_channel=0.5), #Brightness\n",
    "      iaa.FrequencyNoiseAlpha(\n",
    "        exponent=(-1, 0),\n",
    "        first=iaa.Multiply((0.7, 1.3), per_channel=True),\n",
    "        second=iaa.LinearContrast((0.8, 1.3))\n",
    "      ),\n",
    "  ])\n",
    "\n",
    "train_path = \"train_v1-100k\"\n",
    "test_path = \"test_v1-100k\"\n",
    "Path(train_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(test_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_resized_count = len(os.listdir(\"dataset_resized\"))  # ok 13_000 jest\n",
    "desired_count = 100_000\n",
    "i = 0\n",
    "\n",
    "while desired_count > i:\n",
    "    for image in tqdm(os.listdir(\"dataset_resized\")):\n",
    "        img = cv2.imread(join(\"dataset_resized\", image))\n",
    "        imgs = np.array([img])\n",
    "        image_aug = seq(images=imgs)[0]\n",
    "\n",
    "        image_split = image.split('.')\n",
    "        filename = image_split[0] + f\"_augid{i}.\" + image_split[1]\n",
    "        train_gray = cv2.cvtColor(image_aug, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(join(train_path, filename), train_gray)\n",
    "\n",
    "        test_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(join(test_path, filename), test_gray)\n",
    "\n",
    "        i += 1\n",
    "        if i > desired_count:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
